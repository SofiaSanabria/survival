---
title: "survival + random forests for churn"
author: "pedro.concejerocerezo@telefonica.com"
date: "10 de noviembre de 2015"
output: html_document
---

#Setup your R environment 

Be sure to change your directory:

```{r}

setwd("d:/survival")

```

Load (and install if necessary) the required libraries (but see below special requirement about the randomForestSRC library). 

```{r, echo=TRUE, results='hide'}

list.of.packages <- c("survival", 
                      "caret",
                      "glmnet",
                      "rms",
                      "doParallel",
                      "risksetROC")

new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(survival, quietly = TRUE)
library(caret, quietly = TRUE)
library(glmnet, quietly = TRUE)
library(rms, quietly = TRUE)
library(risksetROC, quietly = TRUE)

library(doParallel, quietly = TRUE)                    
registerDoParallel(detectCores() - 1 )  ## registerDoMC( detectCores()-1 ) in Linux

detectCores()
options(rf.cores = detectCores() - 1, 
        mc.cores = detectCores() - 1)  ## Cores for parallel processing


```

Read more about [doParallel](https://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf).

By default, doParallel uses multicore functionality on Unix-like systems and snow functionality on Windows. Note that the multicore functionality only runs tasks on a single computer, not a cluster of computers.

randomForestSRC package allows parallelization but the library binaries are different for Windows and Linux, so you must go to [Hemant Ishwaran's rfsrc page](http://www.ccs.miami.edu/~hishwaran/rfsrc.html) and download the zip file and install it as source.

My system is a windows 7 machine, so I am using that zip. Use the appropriate one for your platform. Let's also check it loads. 

```{r}

install.packages("http://www.ccs.miami.edu/~hishwaran/rfsrc/randomForestSRC_1.6.0.zip", 
                 repos = NULL, 
                 type = "source")

library(randomForestSRC)

```

And only after this you can install ggRandomForests, with very useful plotting functions for the random forests objects created with randomForestSRC.

```{r}

install.packages("ggRandomForests", 
                 repos = 'http://cran.us.r-project.org') #since you had source before
library(ggRandomForests)

```


# Load and explore the data

I found these churn Datasets suggested at 

http://stackoverflow.com/questions/27080207/survival-analysis-for-telecom-churn-using-r

Churn data (artificial based on claims similar to real world). Data are part of UCI machine learning training sets, also more quickly found at[http://www.sgi.com/tech/mlc/db/](http://www.sgi.com/tech/mlc/db/)


```{r}


nm <- read.csv("http://www.sgi.com/tech/mlc/db/churn.names", 
               skip = 4, 
               colClasses = c("character", "NULL"), 
               header = FALSE, 
               sep = ":")[[1]]

dat <- read.csv("http://www.sgi.com/tech/mlc/db/churn.data", 
                header = FALSE, 
                col.names = c(nm, "Churn"),
                colClasses = c("factor",
                               "numeric",
                               "factor",
                               "character",
                               rep("factor", 2),
                               rep("numeric", 14),
                               "factor"))


# test data

test <- read.csv("http://www.sgi.com/tech/mlc/db/churn.test", 
                header = FALSE, 
                col.names = c(nm, "Churn"),
                colClasses = c("factor",
                               "numeric",
                               "factor",
                               "character",
                               rep("factor", 2),
                               rep("numeric", 14),
                               "factor"))

```

This is a quick exploration of training dataset. You have 3333 unique customer id's (phone numbers), account.length is the age (time dimension), which seems to be months, but I am not totally sure, and you have 15% drop-outs, which is a quite high churn rate but then consider we have >10 years span.

```{r}
dim(dat)
summary(dat)
length(unique(dat$phone.number))
hist(dat$account.length)
table(dat$Churn)/nrow(dat)*100

```

And about the test set. You have exactly 1667 rows, exactly half of the training set.

```{r}
summary(test);dim(test)
```


# Random Forests

Random Forests (RF) is a machine learning technique which builds a large number of decision trees that:
- are based on bootstrap samples. Each tree is based on a random sample with replacement of all observations.
- each tree division is based on a random sample of predictors.
- There is no prunning, trees are as long as possible, they are not "cut"

For building each RF tree a part of the observations is not used(37% aprox.). This is called out-of-bag -OOB- sample and is used for a honest estimate of the model predictive capability.

Random Survival Forest (RSF) es la extensión de RF para datos de 
supervivencia
• Propiedades de Random Forest
– Analiza eficientemente un gran número de variables, sin tener que 
hacer selección previa
– Es un método no paramétrico, ya que no hace supuestos sobre el 
modelo. Puede incorporar relaciones no linealese interacciones
– En supervivencia, no asume el principio de riesgos proporcionales
• Random Forest tiene dos parámetros de tuning: el número de árboles y el 
número de predictores que son evaluados en cada división

La construcción de cada árbol de RSF se basa en el particionamiento 
recursivo, donde cada nodo es dividido en dos nodos hijos, seleccionando el 
predictor que maximiza la diferencia en supervivenciaen los nodos hijos
• Test log-rank
– El test log-rank es el método estándar para evaluar si hay diferencias 
significativasen la función de supervivencia entre dos o más grupos
– En cada nodo, se calcula el estadístico del test log-rank para todos 
los predictores evaluados en esa partición 
• Todos los puntos de corte posibles de los predictores continuos
• Todas las combinaciones de categorías en los predictores categóricos
– Se elige como mejor partición la que generan el predictor y el punto de 
corte con el máximo estadístico del test 

Se suele establecer un número mínimo de eventos en los nodos terminales
40 Supervivencia. Alta Dimensionalidad
Random Survival Forest. Predicciones
• En RSF, se estiman la función de supervivencia y la función de riesgo 
acumulado(“cumulative hazard”) para cada observación (Kaplan-Meir)
– En primer lugar, se estiman en los nodos terminales de cada árbol 
– Después, se promedianlos valores de estas funciones en todos los árboles

Para establecer en RSF una predicción numérica por observación se 
suma la función de riesgo acumulada en todos los tiempos
– Es equivalente a un risk score, cuyos valores más altos corresponden a las 
observaciones con mayor riesgo, con peor supervivencia
• Las predicciones para cada observación, se pueden basar en todos los 
árboles o solo en los que no participó en su construcción (OOB sample)
– OOB ensemble cumulative hazard estimator
• En RSF, se define la Tasa de Error = 1 – C-index

Importancia de las Variables
– La estimación del error está basada en la muestra OOB
– Para evaluar la importancia de la variable X, se permutan 
aleatoriamente los valores de esa variable en la muestra OOB, y se 
vuelve a calcular el error
– La Importancia de la variable (VIMP) se define como la diferencia entre 
esos dos errores promediada sobre todos los árboles 
• Si el error aumenta al permutar los valores de la variable significa que esa 
variable es importante, ya que se obtenía un error menor con los valores 
observados

El coste computacional es alto
– Se permutan los valores de todas las variables en todos los árboles
– Para establecer adecuadamente la importancia de las variables en el modelo, hay 
que valorar el uso de un número grande de árboles, para que todas las variables 
tenga la oportunidad de participar en la construcción de bastantes árboles
42 Supervivencia. Alta Dimensionalidad
Random Forest en R
• El paquete randomForest es el paquete habitual que se ha usado en R para 
construir modelos de Random Forest para problemas de clasificacióny 
regresión
• El paquete randomSurvivalForestes el que se usaba para problemas de 
supervivencia, pero ya no se mantiene 

El paquete randomForestSRCes el nuevo paquete que integra los 2 
anteriores, y por tanto permite construir modelos de clasificación, 
regresión y supervivencia
– Permite paralelización
• El paquete ggRandomForestses un paquete que permite explorar los 
modelos construidos
– Extrae los objetos generados por randomForestSRCy genera gráficos con el 
paquete ggplot2, pudiéndose usar los comandos de este paquete para modificar 
los gráficos

La función rfsrc() se usa para construir un modelo de Random Forest  
• Parámetros
– formula :  formula con la variable respuesta y los predictores
– data : data frame que contiene los datos
– ntree:  número de árboles
– mtry:  número de variables que entran como candidatas en cada división 
Por defecto: sqrt(p) en clasificación y supervivencia y p/3 en regresión
– nodesize : número mínimo de observaciones en un nodo terminal (survival, 3) 
– nsplit : número de puntos aleatorios a explorar en los predictores continuos
– importance = T : método para calcular la importancia de las variables
Poned importance=“none” si no se desea usar
– proximity = T : para calcular la matriz de proximidades entre observaciones

rfsrc requires all data to be either numeric or factors.

See error:
Error in finalizeData(c(yvar.names, xvar.names), data, na.action, miss.flag) : 
  data types cannot be character: please convert all characters to factors

In particular we must take out phone number. We also know that state does not predict anything.

```{r}

dat$phone.number <- NULL
dat$state <- NULL
dat$area.code <- NULL

dat$international.plan <- as.numeric(dat$international.plan) - 1

dat$voice.mail.plan <- as.numeric(dat$voice.mail.plan) - 1

dat$Churn <- as.numeric(dat$Churn) - 1

summary(dat)

```

Issues with factors

1. Families

There are four families of random forests:
regression forests for continuous responses
classification forests for factor responses
Survival forests for right-censored survival settings
competing risk survival forests for competing risk scenarios

2. Allowable data types and issues related to factors

Data types must be real valued, integer, factor or logical –however all except factors are
coerced and treated as if real valued. For ordered factors, splits are similar to real valued
variables.   

If the factor is unordered, a split will move a subset of the levels in the parent
node to the left daughter, and the complementary subset to the right daughter.  
All possible complementary pairs are considered and apply to factors with an unlimited number of levels. However, there is an optimization check to ensure that the number of splits attempted is not greater than the number of cases in a node (this internal check will override the nsplit value in random splitting mode if nsplit is large enough; see below for information about nsplit)


```{r}

out.rsf.1 <- rfsrc(Surv(account.length, Churn) ~ . , 
                   data = dat,
                   ntree = 50, 
                   nsplit = 2)

out.rsf.1

```

El objeto $importance contiene la importancia de las variables, en el mismo orden 
en que aparecen en el dataframe. Utilizamos la función sort() para ordenarlas

```{r}

imp.rsf.1 <- sort(out.rsf.1$importance, 
                  decreasing = T)

imp.rsf.1

plot(gg_vimp(out.rsf.1))


```


Let's check C-index


## Predicción. Suma de la función de Riesgo

```{r}

length( out.rsf.1$predicted.oob )

head( out.rsf.1$predicted.oob )

sum.chf.oob = apply ( out.rsf.1$chf.oob , 1, sum ) 

head ( sum.chf.oob )

## OOB Error = 1 – C-index
rcorr.cens(out.rsf.1$predicted.oob, 
           Surv(dat$account.length, dat$Churn))["C Index"]

err.rate.rsf = out.rsf.1$err.rate [ out.rsf.1$ntree ]
err.rate.rsf

## C-index ( Mayor supervivencia se relaciona con menor riesgo )  
rcorr.cens(- out.rsf.1$predicted.oob, 
           Surv(dat$account.length, dat$Churn))["C Index"]

```


Para establecer el número de árboles óptimo, utilizamos la opción importance=“none” para que no estime la importancia de las variables y el coste computacional sea menor
• Usamos la función gg_error() del paquete ggRandomForests
• El OOB Error Rate converge a partir de un número de árboles entre 1500 y 2000  

```{r}

out.rsf.3 <- rfsrc( Surv(account.length, Churn) ~ . , 
                   data = dat, 
                   ntree = 200, 
                   importance = "none", 
                   nsplit = 1)
out.rsf.3

## Gráfico del OOB Error frente al número de árboles
plot( gg_error ( out.rsf.3 ) )

```


Aplicado a test

Remember, make same mods to test set!!!
Avoid
Error in generic.predict.rfsrc(object, newdata, importance = importance,  : 
  x-variable factors from test data do not match original training data


```{r}

test$phone.number <- NULL
test$state <- NULL
test$area.code <- NULL

test$international.plan <- as.numeric(test$international.plan) - 1

test$voice.mail.plan <- as.numeric(test$voice.mail.plan) - 1

test$Churn <- as.numeric(test$Churn) - 1

summary(test)

```



```{r}

pred.test.fin = predict( out.rsf.3, 
                         newdata = test, 
                         importance = "none" )

rcorr.cens(- pred.test.fin$predicted , 
             Surv(test$account.length, test$Churn))["C Index"]

```


risksetROC

at median time

```{r}

w.ROC = risksetROC(Stime = dat$account.length,  
                   status = dat$Churn, 
                   marker = out.rsf.3$predicted.oob, 
                   predict.time = median(dat$account.length), 
                   method = "Cox", 
                   main = paste("OOB Survival ROC Curve at t=", 
                                median(dat$account.length)), 
                   lwd = 3, 
                   col = "red" )
                          
w.ROC$AUC

```

check AUC across time

```{r}

w.ROC = risksetAUC(Stime = dat$account.length,  
                   status = dat$Churn, 
                   marker = out.rsf.3$predicted.oob,
                   tmax = 250)

```

check AUC for test

```{r}

w.ROC = risksetAUC(Stime = test$account.length,  
                   status = test$Churn, 
                   marker = pred.test.fin$predicted, 
                   tmax = 220, 
                   method = "Cox")

```

And with a plot, at good local maximum prediction time, 190.

```{r}

w.ROC = risksetROC(Stime = test$account.length,  
                   status = test$Churn, 
                   marker = pred.test.fin$predicted, 
                   predict.time = 190, 
                   method = "Cox", 
                   main = paste("OOB Survival ROC Curve at t=190"), 
                   lwd = 3, 
                   col = "red" )
 
w.ROC$AUC

```

And with a plot, at maybe best prediction time, 220.

```{r}

w.ROC = risksetROC(Stime = test$account.length,  
                   status = test$Churn, 
                   marker = pred.test.fin$predicted, 
                   predict.time = 220, 
                   method = "Cox", 
                   main = paste("OOB Survival ROC Curve at t=220"), 
                   lwd = 3, 
                   col = "red" )
 
w.ROC$AUC

```

